---
title: "Ronny Kohavi - 播客摘要"
description: ""
pubDate: "2026-01-15"
guest: "Ronny Kohavi"
---

# Ronny Kohavi - 播客摘要

## 嘉宾简介

Ronny Kohavi 被许多人视为A/B测试和实验的世界级专家。最近他是Airbnb的相关性副总裁和技术研究员，领导搜索体验团队。在此之前，他是微软的企业副总裁，领导微软实验平台团队。更早之前，他是亚马逊的数据挖掘和个人化总监。他是《Trustworthy Online Controlled Experiments》一书的作者，这是关于实验的权威书籍。

## 核心议题

- 何时应该考虑在公司开始运行实验
- 如何改变公司文化使其更加数据驱动
- 实验无效的迹象是什么
- 为什么信任是成功实验文化和平台的最重要元素
- 如何开始在公司运行实验
- 什么是P值以及Twyman定律
- 关于Airbnb和实验的一些热点观点

## 核心洞察

### 最令人惊讶的A/B测试案例

**Bing广告标题重组实验**
- 将广告第二行提升到第一行，使标题行变大
- 在backlog中闲置数月，被认为是个"meh"的想法
- 实施成本仅几天时间
- 结果：收入增长12%，价值1亿美元
- 没有损害用户体验指标
- 这是Bing历史上最大的收入增长点

**打开新标签页实验**
- 点击搜索结果时在新标签页打开
- 2008年在英国Hotmail首次测试
- 设计师强烈反对，用户也没要求
- 结果：非常积极的效果
- 后来在Airbnb也采用，但被遗忘，后来重新引入又取得好效果

### 实验失败率

- **微软整体**：约66%的实验失败（2/3）
- **Bing**（高度优化领域）：约85%失败率
- **Airbnb**：92%的实验失败率（最高观察值）
- **Booking、Google Ads**等其他公司：80-90%失败率

**关键教训**：每个开始运行实验的团队都认为自己会不同，但最终都会被数据教育得谦卑。

### 关于"金块"实验

- 一小时工作带来巨大结果的情况非常罕见
- 大多数收益是一寸一寸累积的
- **Bing相关性团队**：每年目标改善2%，通过许多小改进（0.1%、0.15%、0.2%）累积
- **Airbnb搜索**：250个实验最终带来6%的收入提升，但92%失败了

### 资源分配建议

- **70%**：已知方向的增量改进
- **20%**：高风险、高回报的想法（80%会失败，但成功的会是全垒打）
- **10%**：基础设施

## 心法与原则

### 实验哲学

**1. 测试一切 (Test Everything)**
- 任何代码变更、任何功能都应该在实验中
- 即使是小的bug修复也可能有意想不到的影响
- 不可能过度实验

**2. Twyman定律**
"任何看起来有趣或不同的数字通常是错的"
- 如果结果看起来太好而不真实，庆祝晚餐先别吃
- 10次中有9次会发现实验有缺陷
- 第一个Bing广告实验是罕见的例外，经过多次验证

**3. 谦逊原则**
- 我们非常不擅长预测实验结果
- 直觉经常是错的
- 数据是最终的"神谕"

### 关于信任

**信任是实验平台的基础**
- 实验平台是安全网和神谕
- 安全网：快速终止糟糕的部署
- 神谕：告诉实验结果
- 信任容易建立，也容易失去

**Optimizely的教训**
- 早期允许实时监控P值并在显著时停止
- 这将假阳性率从5%膨胀到30%
- 导致一篇著名的文章"Optimizely几乎让我被解雇"
- 后来修复，但损失了大量市场信任

## 实战手册

### 何时开始A/B测试

**用户规模要求**
- **最少**：数万用户（只能检测大效应）
- **理想**：20万用户以上（魔法数字）
- 对于电商网站，检测至少5%的改善需要约20万用户

**早期阶段建议**
- 在达到规模之前开始建设文化、平台和集成
- 这样一旦达到规模就能立即看到价值

### OEC (Overall Evaluation Criterion) 整体评估准则

**核心问题：你在优化什么？**

错误的OEC：
- ❌ 仅优化收入（容易通过损害用户体验来实现）

正确的OEC：
- ✅ 必须对用户生命周期价值具有因果预测性
- ✅ 平衡短期收益和长期增长
- ✅ 包含对立指标

**搜索引擎示例**
- 可以放更多广告赚钱
- 但会增加用户流失
- 会增加用户找到成功结果的时间
- OEC平衡：在不超过一定用户体验损害的前提下增加收入

**约束优化方法**
- 给定固定的广告位像素预算
- 如果在相同预算下赚更多钱，就通过
- 可以零广告、三个广告或更大广告

**Airbnb示例**
- 不仅看转化率
- 要看用户实际入住后的评分
- 需要构建预测模型

### 实验无效的迹象

**1. 样本比例不匹配 (Sample Ratio Mismatch, SRM)**
- 设计50/50分配，实际得到50.2/49.8
- 如果概率是50万分之1，肯定有问题
- 微软8%的实验有SRM问题

**常见原因**：
- 机器人流量不均衡
- 数据管道问题
- 从网站中间开始实验，忽略了侧面活动流量

**解决方案**：
- 平台应该自动检测并警告
- 结果用红线标出，截图时能看出问题
- 强制点击按钮才能查看结果

**2. 看起来太好的结果**
- 正常变动<1%，突然10%
- 首先怀疑有问题，而不是庆祝

### 大规模重新设计的建议

**现实**：
- 大部分重新设计都失败了
- 问题在于同时做17个改变，很多会失败
- 沉没成本谬误："我们花了这么长时间，必须发布"

**正确方法**：
1. 分步骤进行并沿途测试
2. 如果不能分解为单因素，就分解为小部分
3. 学习小改变中什么有效什么无效
4. 80%会失败，做好心理准备
5. 如果相信需要突破局部最小值，可以尝试，但准备好失败

### 实验平台建设

**目标**：将实验的边际成本降至接近零

**6个发展阶段**（从crawl到fly）：
1. 配置
2. 随机化
3. 指标
4. 实验
5. 分析
6. 文化

**平台特征**：
- 自助服务设置实验
- 快速分析结果
- 不需要数据科学家介入
- 自动检测SRM和其他问题

### 提高实验速度

**1. 平台自动化**
- 实验结束后立即生成记分卡
- 不应该等一周让数据科学家分析

**2. 方差减少技术**
- **封顶指标**：收入超过$1000计为$1000
- **CUPED方法**：使用实验前数据调整结果
- 需要更少用户获得统计显著性

**3. 重复验证**
- 对于0.01 < p < 0.05的结果，重新运行
- 使用Fisher方法或Stouffer方法合并p值

## 反常识视角

### P值的误解

**错误理解**：
- p = 0.02 意味着98%概率处理组优于对照组
- 这是最常见的错误解释

**正确理解**：
- p值假设零假设为真
- 它计算的是在零假设下看到当前数据的概率
- 需要贝叶斯规则反转概率
- 需要先验概率（历史成功率）

**假阳性风险示例**：
- 在Airbnb（成功率8%），p < 0.05的结果
- 实际假阳性风险是26%，不是5%！
- 这就是为什么需要更严格的p值或重复验证

### 完美重新设计的迷思

- 每次全面重新设计都没产生积极结果
- 团队最终必须撤回并弄清楚搞砸了什么
- 问题在于花了3-6个月建立，此时"必须发布"
- 3-6个月的工作会因为糟糕的结果而浪费

### 邮件营销的案例

**初始做法**：
- 用户从邮件点击购买就给邮件团队功劳
- 导致发送更多邮件
- 结果：垃圾邮件

**修正**：
- 建模取消订阅的成本
- 发现一个取消订阅损失几美元的长期价值
- 引入对立指标后，超过一半的营销活动实际上是负的

**新功能**：
- 默认取消订阅是针对特定活动
- 大幅减少对立指标
- 可以发送更多邮件

### 关于社会功能

**Bing的社会整合尝试**：
- 接入Twitter和Facebook
- 投入100人年
- 持续1.5年
- 结果：失败，所有实验都是负面或平坦
- 最终被放弃

**类似案例**：
- Netflix的社会功能尝试失败
- Airbnb早期的朋友推荐功能毫无影响

### COVID期间的实验

**常见观点**：
- 危机期间必须快速决策，不应该测试

**Ronny的观点**：
- 和平时期你都错2/3到80%的时间
- 为什么战时（COVID）你会突然正确？
- 实际上在危机期间测试更重要
- 可以看到在当前环境中是否有帮助
- Airbnb如果什么都不做，收入也会以同样的方式上升

### Amazon的六页纸

**Jeff Bezos的邮件**：
- "不再用PowerPoint"
- 强迫写叙述性文档

**影响**：
- 结构化叙述
- 团队审查
- 诚实反馈
- 会议后记录保留
- 影响惊人

## 花絮与细节

### 个人经历

**从Amazon到Microsoft**
- 加入一个月后团队解散
- 人们问："你刚来，怎么帮Microsoft？"
- 决定建设实验平台
- 反应："我们的PM更好"
- 3年开发周期 vs 持续实验
- Bing率先大规模实施
- 数据证明大多数想法失败
- 最终Office也采用

**在Airbnb**
- 搜索相关性团队一切都做A/B测试
- 250个实验，6%收入提升
- 92%失败率
- 有限但允许分享的信息

### 推荐资源

**书籍**：
1. *Calling Bullshit* - 揭穿极端说法
2. *Hard Facts, Dangerous Half-Truths And Total Nonsense* - Stanford商学院教授
3. *Mistakes Were Made (But Not by Me)* - 关于认知谬误

**网站**：
- **goodui.org** - 140个UI模式，哪些有效
- **Rules of Thumb paper** - 从数千实验提取模式

**最近的喜爱产品**：
- Blink摄像头
- 两节AA电池用6个月
- 发现不知道的事情（如动物经过）

### 最喜欢的面试问题

技术面试：
- "告诉我static限定符在C++中做什么"
- 超过50%的工程面试者答错或答得很糟糕

### 关于Airbnb的热点观点

- 限制能分享的内容
- 其他团队有的测试有的不测试
- Brian Chesky更少关注实验
- 认为如果保持更多数据驱动（如Greg Greeley推动的），会处于更好状态
- 在线体验的初始数据不promising，现在只是注脚
- 反事实：不知道如果继续实验会怎样

### 书籍成功

- Cambridge预测卖几千本
- 实际销售超过20,000本英文版
- 翻译成中文、韩文、日文、俄文
- 所有收益捐给慈善
- 作者没有财务收益

### 组织学习

**季度最有趣实验会议**：
- 不仅关注赢家
- 关注令人惊讶的失败者
- 分享成功和失败
- 帮助实验的飞轮

**制度记忆**：
- 记录学习
- 搜索数千实验历史
- 10%实验第一天被中止（通常是bug，不是想法不好）

## 最终建议

### 开始实验的步骤

1. **评估build vs buy**
   - 今天有好的第三方产品
   - 早期Amazon和Microsoft必须自建
   - 通常是两者结合

2. **找到桥头堡团队**
   - 频繁发布的团队
   - 不是每6个月或3年发布一次
   - Bing每天多次发布

3. **明确OEC**
   - 确保方向上大家同意
   - 微软.com网站的"time on site"争议
   - 支持网站：时间多好还是坏？

4. **投资平台**
   - 降低边际成本到零
   - 自动化分析
   - 减少对数据科学家的依赖

5. **关注信任**
   - 正确的统计方法
   - SRM检测
   - Twyman定律思维
   - 不要发布平坦的结果（除非法律要求）

### 文化改变

**时间线**：
- Microsoft通过Bing桥头堡成功
- 跨团队人员流动帮助传播
- 分享令人惊讶的结果
- 证明有更好的构建软件的方式

**核心信息**：
- 使用科学
- 受控实验是做出正确数据驱动决策的机制
- 谦逊：大多数想法会失败
- 持续改进胜过完美

---

*基于Lenny's Podcast with Ronny Kohavi的访谈整理*
